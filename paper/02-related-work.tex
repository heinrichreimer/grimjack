\section{Related Work}
    Since the shared task, we participated in is in its third edition this year the most related work has been done in the two previous years. So we will have a look at the years 2020 and 2021 of the Touché shared task 2: Answering of Comparative Questions.
    \subsection{Touchè 2020: Argument Retrieval}
        In 2020 the task was to retrieve documents from the ClueWeb12 corpus to answer comparative questions like \textit{Is X better than Y with respect to Z?}. The resulting documents should contain documents with convincing arguments for or against the comparative questions in contrast to current search engines which may display only one (short) answer. For this task, five teams submitted eleven runs. We now will have a look at the two best runs: Team Bilbo Baggins and Team Inigo Montoya~\cite{BondarenkoFBGAPBSWPH2020}\par
        Team Bilbo Baggins has developed a retrieval pipeline with four steps. In their first one, they analyze the query and determine entities that compare. Then they expand the queries with synonyms and antonyms of the found entities and send those queries to ChatNoir\footnote{\url{https://www.chatnoir.eu/}}. In the second step, they conduct argument mining and calculate the document quality by evidence mining and link analysis. The third step consists of summing up the collected scores and building relevance, support, and credibility scores. In their final step, they build weighting scores and rerank the documents by multiplying the weighting scores with the sum of the aforementioned scores. Team Bilbo Baggins scored first place in 2020 with an NDCG@5 score of 0.580~\cite{AbyeST2020}.\par
        The second place in 2020 (Team Inigo Montoya) queries ChatNoir with the original queries and processes the first 20 results further. These results are sent to TARGER~\cite{ChernodubOHBHBP2019} to determine their premise and claims. Arguments from one web page will then be stored in one document. These argument documents will then be indexed and queried with Okapi BM25 and the top 20 results will be displayed. Team Inigo Montoya scored a NDCG@5 of 0.567~\cite{Huck2020}.
    \subsection{Touchè 2021: Argument Retrieval}
        The task for 2021 was the same as for 2020. So participants were asked to retrieve relevant documents from the ClueWeb12 corpus for comparative questions. However, the provided topics and therefore the queries have been changed. In 2021 there were six submitted runs. We now will have a look at the two best runs regarding the NDCG@5: Team Katana and Team Thor~\cite{BondarenkoFBGAPBSWPH2021}\par
        Team Katana queries the search engine ChatNoir with the provided topics and extracts up to 100 unique documents from the result set. Then they clean the documents. After that, they rerank the documents by one of their developed models. Their models are feature-based machine learning models with features from PyTerrier, specific comparative features, and scores from the ChatNoir system. They developed the following ranking models: (1) an XGBoost approach, (2) a LightGBM approach, (3) Random Forests, and (4) a BERT-based
        ranker. Team Katana scored first place with an NDCG@5 of 0.489~\cite{ChekalinaP2021}.\par
        Team Thor queries the search engine ChatNoir with an AND-Operator and removes every punctation from the topics and the documents found. Additionally, they remove all boilerplate from the documents to extract the main content. Then they create an index with Elasticsearch of the first 110 documents returned by ChatNoir. After that, they expand the original query with synonyms from WordNet. Here for every word synonyms will be calculated. Lastly, they query their index with Okapi BM25 (b=0.68 and k1=1.2). Team Thor achieved an NDCG@5 of 0.478~\cite{ShirshakovaW2021}. 

