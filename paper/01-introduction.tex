\section{Introduction}
    Current information retrieval systems are well able to answer keyword queries and also simple questions but will struggle with comparative questions due to their complex linguistic structure and ambigious information need.  It is also challenging to retrieve  a non biased and balanced result set for comparative questions since not every comparative questions will have a balanced set of arguments for and against it. When asking such comparative questions users do want to see as much as possible arguments for their question  ordered by strength of the arguments. So systems which want to answer such questions must be able to determine argument quality and also their stance to classify which argument is for or against the comparative object.
    Answering comparative questions will support users in their everyday lifes since those questions arise very often and users might struggle with converting those questions in key word queries. Understanding and answering comparative questions will also have the benefit of being able to recognize the user's information need better than simple key word queries could accomplish this. 
    \par
    During the winter semester 2021/202 we have participated in the Shared Task 2 of the CLEF Argument Retrieval 2022. The task was to retrieve relevant passages from a subset of the ClueWeb12 corpus for 50 provided comparative questions. Furthermore, the stance of the passages regarding the comparative object should be determined. To accomplish this task we developed an approach which consists of four components. The first component is a query reformulation step which combines different queries to one query. The second component retrieves passages with this new query. Our third component determines the argument quality and the stance towards the comparative objects. The last component is an axiomatic reranker which incorporates argument quality and other various features to rerank the retrieved passages. The mentioned components will be discussed in depth in chapter \ref{approach}. The approach has been coded in Python and anserini has been used to accomplish the indexing step and the retrieval step.   